{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import langid\n",
    "from langdetect import detect, DetectorFactory\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import scipy\n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import chi2, f_regression , mutual_info_classif\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "path = 'DataSet' # use your path\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename)\n",
    "    li.append(df)\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame = frame.drop(frame[frame['Classification'].isnull()].index)\n",
    "frame.dropna(subset=['Reviews/Comments'], inplace=True)\n",
    "frame  = frame.sort_values('Feedback ID')\n",
    "frame.to_excel(\"Input.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OYO ID</th>\n",
       "      <th>Hotel ID</th>\n",
       "      <th>OYO Product</th>\n",
       "      <th>Feedback ID</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Rating</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>Reviews/Comments</th>\n",
       "      <th>...</th>\n",
       "      <th>Comfort</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Location</th>\n",
       "      <th>Customer Support</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Food</th>\n",
       "      <th>Payment</th>\n",
       "      <th>Pricing</th>\n",
       "      <th>Default</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>MRT042</td>\n",
       "      <td>46039.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60144582.0</td>\n",
       "      <td>118672380.0</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I had a great stay. Hotel staff was very suppo...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>KOL1340</td>\n",
       "      <td>82429.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60156829.0</td>\n",
       "      <td>118141552.0</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worst ever OYO experienced. No OYO sign board,...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>ASR293</td>\n",
       "      <td>58291.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60168982.0</td>\n",
       "      <td>118586097.0</td>\n",
       "      <td>bulk_upload</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One of the best properties we have ever been i...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>GRG1010</td>\n",
       "      <td>40843.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60178229.0</td>\n",
       "      <td>118844212.0</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Everything is good no complaints staff behavio...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>DEL775</td>\n",
       "      <td>15322.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60179150.0</td>\n",
       "      <td>118417540.0</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One of the best hotel through OYO. I recommend...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>GZB108</td>\n",
       "      <td>46852.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61382951.0</td>\n",
       "      <td>121800300.0</td>\n",
       "      <td>IOS App</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The curtains were very thin and incapable to k...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>SRG102</td>\n",
       "      <td>56126.0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61390504.0</td>\n",
       "      <td>117518389.0</td>\n",
       "      <td>Android App</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No local ids cards accepted and unmarried coup...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>DEL1593</td>\n",
       "      <td>57984.0</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>61390678.0</td>\n",
       "      <td>122345895.0</td>\n",
       "      <td>Crs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wash room was not clean \\n room was not clean....</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>KOL1040</td>\n",
       "      <td>57161.0</td>\n",
       "      <td>Silverkey</td>\n",
       "      <td>61392769.0</td>\n",
       "      <td>121787462.0</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The manager with tall hieght told to leave the...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Discard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>MUM1123</td>\n",
       "      <td>59540.0</td>\n",
       "      <td>CapitalO</td>\n",
       "      <td>61395280.0</td>\n",
       "      <td>122677830.0</td>\n",
       "      <td>Crs</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it was good stay....reception people was very ...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2389 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OYO ID  Hotel ID OYO Product  Feedback ID   Booking ID       Source  \\\n",
       "1062   MRT042   46039.0       SMART   60144582.0  118672380.0  Android App   \n",
       "283   KOL1340   82429.0       SMART   60156829.0  118141552.0  Android App   \n",
       "737    ASR293   58291.0       SMART   60168982.0  118586097.0  bulk_upload   \n",
       "1465  GRG1010   40843.0       SMART   60178229.0  118844212.0  Android App   \n",
       "654    DEL775   15322.0       SMART   60179150.0  118417540.0  Android App   \n",
       "...       ...       ...         ...          ...          ...          ...   \n",
       "989    GZB108   46852.0       SMART   61382951.0  121800300.0      IOS App   \n",
       "842    SRG102   56126.0       SMART   61390504.0  117518389.0  Android App   \n",
       "2199  DEL1593   57984.0   Townhouse   61390678.0  122345895.0          Crs   \n",
       "1134  KOL1040   57161.0   Silverkey   61392769.0  121787462.0  Android App   \n",
       "1149  MUM1123   59540.0    CapitalO   61395280.0  122677830.0          Crs   \n",
       "\n",
       "      Rating  L1  L2                                   Reviews/Comments  ...  \\\n",
       "1062     5.0 NaN NaN  I had a great stay. Hotel staff was very suppo...  ...   \n",
       "283      1.0 NaN NaN  Worst ever OYO experienced. No OYO sign board,...  ...   \n",
       "737      0.0 NaN NaN  One of the best properties we have ever been i...  ...   \n",
       "1465     5.0 NaN NaN  Everything is good no complaints staff behavio...  ...   \n",
       "654      5.0 NaN NaN  One of the best hotel through OYO. I recommend...  ...   \n",
       "...      ...  ..  ..                                                ...  ...   \n",
       "989      3.0 NaN NaN  The curtains were very thin and incapable to k...  ...   \n",
       "842      3.0 NaN NaN  No local ids cards accepted and unmarried coup...  ...   \n",
       "2199     1.0 NaN NaN  Wash room was not clean \\n room was not clean....  ...   \n",
       "1134     1.0 NaN NaN  The manager with tall hieght told to leave the...  ...   \n",
       "1149     3.0 NaN NaN  it was good stay....reception people was very ...  ...   \n",
       "\n",
       "      Comfort  Direction  Location  Customer Support  Breakfast   Food  \\\n",
       "1062     True      False     False             False      False  False   \n",
       "283      True       True      True             False      False  False   \n",
       "737     False      False     False             False      False  False   \n",
       "1465    False      False     False             False      False  False   \n",
       "654     False      False     False             False      False  False   \n",
       "...       ...        ...       ...               ...        ...    ...   \n",
       "989      True      False     False             False      False  False   \n",
       "842     False      False     False             False      False  False   \n",
       "2199    False      False     False             False      False  False   \n",
       "1134    False      False     False             False      False  False   \n",
       "1149     True      False     False             False      False  False   \n",
       "\n",
       "      Payment  Pricing  Default  Classification  \n",
       "1062    False    False    False            Good  \n",
       "283     False    False    False             Bad  \n",
       "737     False    False     True            Good  \n",
       "1465    False    False    False            Good  \n",
       "654     False    False    False            Good  \n",
       "...       ...      ...      ...             ...  \n",
       "989     False    False    False             Bad  \n",
       "842     False    False     True             Bad  \n",
       "2199    False    False    False             Bad  \n",
       "1134    False    False    False         Discard  \n",
       "1149     True    False    False            Good  \n",
       "\n",
       "[2389 rows x 31 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification\n",
      "Average     194\n",
      "Bad        1153\n",
      "Discard     179\n",
      "Good        862\n",
      "Name: Feedback ID, dtype: int64\n",
      "CPU times: user 724 ms, sys: 0 ns, total: 724 ms\n",
      "Wall time: 723 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel(\"Input.xlsx\")\n",
    "unique_sentiments_count = df.groupby('Classification')['Feedback ID'].nunique()\n",
    "print(unique_sentiments_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import langid\n",
    "\n",
    "def clean_text_round1(text,punctuation):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), ' ', text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "punctuation = string.punctuation.replace(\"'\",\"\")\n",
    "punctuation = punctuation + \"0123456789\"\n",
    "df['comment(1cleaning)'] = df['Reviews/Comments'].apply(lambda x: clean_text_round1(x,punctuation))\n",
    "df['langid'] = df['Reviews/Comments'].apply(lambda x: langid.classify(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', \"aren't\", 'couldn', \"couldn't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", 'ma', \"mightn't\", \"mustn't\", \"needn't\", \"shan't\", 'shouldn', 'wasn', \"weren't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "\n",
    "stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "            \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", \n",
    "            'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \n",
    "            'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', \n",
    "            'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of',\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "            'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', \n",
    "            'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', \n",
    "            'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', \n",
    "            'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", \n",
    "            \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', \"aren't\", 'couldn', \n",
    "            \"couldn't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", 'ma', \"mightn't\", \"mustn't\", \"needn't\" , \"shan't\", 'shouldn', 'wasn', \"weren't\"]\n",
    "\n",
    "\n",
    "print(stop)\n",
    "dir(nltk.corpus)\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "    \n",
    "def clean_text_round2(text):\n",
    "    # print(text)\n",
    "    text = text.split(\" \")\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    # print(text)\n",
    "    pos_tags = pos_tag(text)\n",
    "    #print(pos_tags)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)     \n",
    "df['lemmatized_comment'] = df['comment(1cleaning)'].apply(lambda x: clean_text_round2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification\n",
      "Average     193\n",
      "Bad        1150\n",
      "Discard     172\n",
      "Good        857\n",
      "Name: Feedback ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(df[df['Classification'].isnull()].index)\n",
    "df = df.drop(df[df['langid'] !='en'].index)\n",
    "df.dropna(subset=['lemmatized_comment'], inplace=True)\n",
    "unique_sentiments_count = df.groupby('Classification')['Feedback ID'].nunique()\n",
    "print(unique_sentiments_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(text):\n",
    "    if(text == 'Good'):\n",
    "        return 1\n",
    "    if(text == 'Bad'):\n",
    "        return 0\n",
    "    return 2\n",
    "\n",
    "df['Class'] = df['Classification'].apply(lambda x: getClass(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OYO ID</th>\n",
       "      <th>Hotel ID</th>\n",
       "      <th>OYO Product</th>\n",
       "      <th>Feedback ID</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Rating</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>...</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Food</th>\n",
       "      <th>Payment</th>\n",
       "      <th>Pricing</th>\n",
       "      <th>Default</th>\n",
       "      <th>Classification</th>\n",
       "      <th>comment(1cleaning)</th>\n",
       "      <th>langid</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1062</td>\n",
       "      <td>MRT042</td>\n",
       "      <td>46039</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60144582</td>\n",
       "      <td>118672380</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>i had a great stay hotel staff was very suppor...</td>\n",
       "      <td>en</td>\n",
       "      <td>great stay hotel staff supportive kind hearted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>KOL1340</td>\n",
       "      <td>82429</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60156829</td>\n",
       "      <td>118141552</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>worst ever oyo experienced no oyo sign board m...</td>\n",
       "      <td>en</td>\n",
       "      <td>worst ever oyo experienced no oyo sign board m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737</td>\n",
       "      <td>ASR293</td>\n",
       "      <td>58291</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60168982</td>\n",
       "      <td>118586097</td>\n",
       "      <td>bulk_upload</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "      <td>one of the best properties we have ever been i...</td>\n",
       "      <td>en</td>\n",
       "      <td>one best property ever would like visit strong...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465</td>\n",
       "      <td>GRG1010</td>\n",
       "      <td>40843</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60178229</td>\n",
       "      <td>118844212</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>everything is good no complaints staff behavio...</td>\n",
       "      <td>en</td>\n",
       "      <td>everything good no complaint staff behaviour p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>654</td>\n",
       "      <td>DEL775</td>\n",
       "      <td>15322</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60179150</td>\n",
       "      <td>118417540</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>one of the best hotel through oyo i recommend ...</td>\n",
       "      <td>en</td>\n",
       "      <td>one best hotel oyo recommend hotel guest room ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>989</td>\n",
       "      <td>GZB108</td>\n",
       "      <td>46852</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61382951</td>\n",
       "      <td>121800300</td>\n",
       "      <td>IOS App</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>the curtains were very thin and incapable to k...</td>\n",
       "      <td>en</td>\n",
       "      <td>curtain thin incapable keep sunlight away cann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>842</td>\n",
       "      <td>SRG102</td>\n",
       "      <td>56126</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61390504</td>\n",
       "      <td>117518389</td>\n",
       "      <td>Android App</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bad</td>\n",
       "      <td>no local ids cards accepted and unmarried coup...</td>\n",
       "      <td>en</td>\n",
       "      <td>no local id card accept unmarried couple not w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2199</td>\n",
       "      <td>DEL1593</td>\n",
       "      <td>57984</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>61390678</td>\n",
       "      <td>122345895</td>\n",
       "      <td>Crs</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>wash room was not clean room was not clean pro...</td>\n",
       "      <td>en</td>\n",
       "      <td>wash room not clean room not clean properly co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>1134</td>\n",
       "      <td>KOL1040</td>\n",
       "      <td>57161</td>\n",
       "      <td>Silverkey</td>\n",
       "      <td>61392769</td>\n",
       "      <td>121787462</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Discard</td>\n",
       "      <td>the manager with tall hieght told to leave the...</td>\n",
       "      <td>en</td>\n",
       "      <td>manager tall hieght tell leave hotel complain ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>1149</td>\n",
       "      <td>MUM1123</td>\n",
       "      <td>59540</td>\n",
       "      <td>CapitalO</td>\n",
       "      <td>61395280</td>\n",
       "      <td>122677830</td>\n",
       "      <td>Crs</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>it was good stay reception people was very rud...</td>\n",
       "      <td>en</td>\n",
       "      <td>good stay reception people rude payment issue ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2373 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   OYO ID  Hotel ID OYO Product  Feedback ID  Booking ID  \\\n",
       "0           1062   MRT042     46039       SMART     60144582   118672380   \n",
       "1            283  KOL1340     82429       SMART     60156829   118141552   \n",
       "2            737   ASR293     58291       SMART     60168982   118586097   \n",
       "3           1465  GRG1010     40843       SMART     60178229   118844212   \n",
       "4            654   DEL775     15322       SMART     60179150   118417540   \n",
       "...          ...      ...       ...         ...          ...         ...   \n",
       "2384         989   GZB108     46852       SMART     61382951   121800300   \n",
       "2385         842   SRG102     56126       SMART     61390504   117518389   \n",
       "2386        2199  DEL1593     57984   Townhouse     61390678   122345895   \n",
       "2387        1134  KOL1040     57161   Silverkey     61392769   121787462   \n",
       "2388        1149  MUM1123     59540    CapitalO     61395280   122677830   \n",
       "\n",
       "           Source  Rating  L1  L2  ... Breakfast   Food  Payment  Pricing  \\\n",
       "0     Android App       5 NaN NaN  ...     False  False    False    False   \n",
       "1     Android App       1 NaN NaN  ...     False  False    False    False   \n",
       "2     bulk_upload       0 NaN NaN  ...     False  False    False    False   \n",
       "3     Android App       5 NaN NaN  ...     False  False    False    False   \n",
       "4     Android App       5 NaN NaN  ...     False  False    False    False   \n",
       "...           ...     ...  ..  ..  ...       ...    ...      ...      ...   \n",
       "2384      IOS App       3 NaN NaN  ...     False  False    False    False   \n",
       "2385  Android App       3 NaN NaN  ...     False  False    False    False   \n",
       "2386          Crs       1 NaN NaN  ...     False  False    False    False   \n",
       "2387  Android App       1 NaN NaN  ...     False  False    False    False   \n",
       "2388          Crs       3 NaN NaN  ...     False  False     True    False   \n",
       "\n",
       "      Default  Classification  \\\n",
       "0       False            Good   \n",
       "1       False             Bad   \n",
       "2        True            Good   \n",
       "3       False            Good   \n",
       "4       False            Good   \n",
       "...       ...             ...   \n",
       "2384    False             Bad   \n",
       "2385     True             Bad   \n",
       "2386    False             Bad   \n",
       "2387    False         Discard   \n",
       "2388    False            Good   \n",
       "\n",
       "                                     comment(1cleaning)  langid  \\\n",
       "0     i had a great stay hotel staff was very suppor...      en   \n",
       "1     worst ever oyo experienced no oyo sign board m...      en   \n",
       "2     one of the best properties we have ever been i...      en   \n",
       "3     everything is good no complaints staff behavio...      en   \n",
       "4     one of the best hotel through oyo i recommend ...      en   \n",
       "...                                                 ...     ...   \n",
       "2384  the curtains were very thin and incapable to k...      en   \n",
       "2385  no local ids cards accepted and unmarried coup...      en   \n",
       "2386  wash room was not clean room was not clean pro...      en   \n",
       "2387  the manager with tall hieght told to leave the...      en   \n",
       "2388  it was good stay reception people was very rud...      en   \n",
       "\n",
       "                                     lemmatized_comment  Class  \n",
       "0     great stay hotel staff supportive kind hearted...      1  \n",
       "1     worst ever oyo experienced no oyo sign board m...      0  \n",
       "2     one best property ever would like visit strong...      1  \n",
       "3     everything good no complaint staff behaviour p...      1  \n",
       "4     one best hotel oyo recommend hotel guest room ...      1  \n",
       "...                                                 ...    ...  \n",
       "2384  curtain thin incapable keep sunlight away cann...      0  \n",
       "2385  no local id card accept unmarried couple not w...      0  \n",
       "2386  wash room not clean room not clean properly co...      0  \n",
       "2387  manager tall hieght tell leave hotel complain ...      2  \n",
       "2388  good stay reception people rude payment issue ...      1  \n",
       "\n",
       "[2373 rows x 36 columns]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.Class==1) | (df.Class==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OYO ID</th>\n",
       "      <th>Hotel ID</th>\n",
       "      <th>OYO Product</th>\n",
       "      <th>Feedback ID</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Rating</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>...</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Food</th>\n",
       "      <th>Payment</th>\n",
       "      <th>Pricing</th>\n",
       "      <th>Default</th>\n",
       "      <th>Classification</th>\n",
       "      <th>comment(1cleaning)</th>\n",
       "      <th>langid</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1062</td>\n",
       "      <td>MRT042</td>\n",
       "      <td>46039</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60144582</td>\n",
       "      <td>118672380</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>i had a great stay hotel staff was very suppor...</td>\n",
       "      <td>en</td>\n",
       "      <td>great stay hotel staff supportive kind hearted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>KOL1340</td>\n",
       "      <td>82429</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60156829</td>\n",
       "      <td>118141552</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>worst ever oyo experienced no oyo sign board m...</td>\n",
       "      <td>en</td>\n",
       "      <td>worst ever oyo experienced no oyo sign board m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737</td>\n",
       "      <td>ASR293</td>\n",
       "      <td>58291</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60168982</td>\n",
       "      <td>118586097</td>\n",
       "      <td>bulk_upload</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "      <td>one of the best properties we have ever been i...</td>\n",
       "      <td>en</td>\n",
       "      <td>one best property ever would like visit strong...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465</td>\n",
       "      <td>GRG1010</td>\n",
       "      <td>40843</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60178229</td>\n",
       "      <td>118844212</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>everything is good no complaints staff behavio...</td>\n",
       "      <td>en</td>\n",
       "      <td>everything good no complaint staff behaviour p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>654</td>\n",
       "      <td>DEL775</td>\n",
       "      <td>15322</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60179150</td>\n",
       "      <td>118417540</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>one of the best hotel through oyo i recommend ...</td>\n",
       "      <td>en</td>\n",
       "      <td>one best hotel oyo recommend hotel guest room ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>905</td>\n",
       "      <td>DEL1525</td>\n",
       "      <td>55641</td>\n",
       "      <td>SPOT ON</td>\n",
       "      <td>61373230</td>\n",
       "      <td>118489815</td>\n",
       "      <td>Integrated OTA</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bad</td>\n",
       "      <td>refused to provide a discount for booking i ca...</td>\n",
       "      <td>en</td>\n",
       "      <td>refuse provide discount book say anything posi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>989</td>\n",
       "      <td>GZB108</td>\n",
       "      <td>46852</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61382951</td>\n",
       "      <td>121800300</td>\n",
       "      <td>IOS App</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>the curtains were very thin and incapable to k...</td>\n",
       "      <td>en</td>\n",
       "      <td>curtain thin incapable keep sunlight away cann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>842</td>\n",
       "      <td>SRG102</td>\n",
       "      <td>56126</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61390504</td>\n",
       "      <td>117518389</td>\n",
       "      <td>Android App</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bad</td>\n",
       "      <td>no local ids cards accepted and unmarried coup...</td>\n",
       "      <td>en</td>\n",
       "      <td>no local id card accept unmarried couple not w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2199</td>\n",
       "      <td>DEL1593</td>\n",
       "      <td>57984</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>61390678</td>\n",
       "      <td>122345895</td>\n",
       "      <td>Crs</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>wash room was not clean room was not clean pro...</td>\n",
       "      <td>en</td>\n",
       "      <td>wash room not clean room not clean properly co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>1149</td>\n",
       "      <td>MUM1123</td>\n",
       "      <td>59540</td>\n",
       "      <td>CapitalO</td>\n",
       "      <td>61395280</td>\n",
       "      <td>122677830</td>\n",
       "      <td>Crs</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>it was good stay reception people was very rud...</td>\n",
       "      <td>en</td>\n",
       "      <td>good stay reception people rude payment issue ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   OYO ID  Hotel ID OYO Product  Feedback ID  Booking ID  \\\n",
       "0           1062   MRT042     46039       SMART     60144582   118672380   \n",
       "1            283  KOL1340     82429       SMART     60156829   118141552   \n",
       "2            737   ASR293     58291       SMART     60168982   118586097   \n",
       "3           1465  GRG1010     40843       SMART     60178229   118844212   \n",
       "4            654   DEL775     15322       SMART     60179150   118417540   \n",
       "...          ...      ...       ...         ...          ...         ...   \n",
       "2383         905  DEL1525     55641     SPOT ON     61373230   118489815   \n",
       "2384         989   GZB108     46852       SMART     61382951   121800300   \n",
       "2385         842   SRG102     56126       SMART     61390504   117518389   \n",
       "2386        2199  DEL1593     57984   Townhouse     61390678   122345895   \n",
       "2388        1149  MUM1123     59540    CapitalO     61395280   122677830   \n",
       "\n",
       "              Source  Rating  L1  L2  ... Breakfast   Food  Payment  Pricing  \\\n",
       "0        Android App       5 NaN NaN  ...     False  False    False    False   \n",
       "1        Android App       1 NaN NaN  ...     False  False    False    False   \n",
       "2        bulk_upload       0 NaN NaN  ...     False  False    False    False   \n",
       "3        Android App       5 NaN NaN  ...     False  False    False    False   \n",
       "4        Android App       5 NaN NaN  ...     False  False    False    False   \n",
       "...              ...     ...  ..  ..  ...       ...    ...      ...      ...   \n",
       "2383  Integrated OTA       2 NaN NaN  ...     False  False    False    False   \n",
       "2384         IOS App       3 NaN NaN  ...     False  False    False    False   \n",
       "2385     Android App       3 NaN NaN  ...     False  False    False    False   \n",
       "2386             Crs       1 NaN NaN  ...     False  False    False    False   \n",
       "2388             Crs       3 NaN NaN  ...     False  False     True    False   \n",
       "\n",
       "      Default  Classification  \\\n",
       "0       False            Good   \n",
       "1       False             Bad   \n",
       "2        True            Good   \n",
       "3       False            Good   \n",
       "4       False            Good   \n",
       "...       ...             ...   \n",
       "2383     True             Bad   \n",
       "2384    False             Bad   \n",
       "2385     True             Bad   \n",
       "2386    False             Bad   \n",
       "2388    False            Good   \n",
       "\n",
       "                                     comment(1cleaning)  langid  \\\n",
       "0     i had a great stay hotel staff was very suppor...      en   \n",
       "1     worst ever oyo experienced no oyo sign board m...      en   \n",
       "2     one of the best properties we have ever been i...      en   \n",
       "3     everything is good no complaints staff behavio...      en   \n",
       "4     one of the best hotel through oyo i recommend ...      en   \n",
       "...                                                 ...     ...   \n",
       "2383  refused to provide a discount for booking i ca...      en   \n",
       "2384  the curtains were very thin and incapable to k...      en   \n",
       "2385  no local ids cards accepted and unmarried coup...      en   \n",
       "2386  wash room was not clean room was not clean pro...      en   \n",
       "2388  it was good stay reception people was very rud...      en   \n",
       "\n",
       "                                     lemmatized_comment  Class  \n",
       "0     great stay hotel staff supportive kind hearted...      1  \n",
       "1     worst ever oyo experienced no oyo sign board m...      0  \n",
       "2     one best property ever would like visit strong...      1  \n",
       "3     everything good no complaint staff behaviour p...      1  \n",
       "4     one best hotel oyo recommend hotel guest room ...      1  \n",
       "...                                                 ...    ...  \n",
       "2383  refuse provide discount book say anything posi...      0  \n",
       "2384  curtain thin incapable keep sunlight away cann...      0  \n",
       "2385  no local id card accept unmarried couple not w...      0  \n",
       "2386  wash room not clean room not clean properly co...      0  \n",
       "2388  good stay reception people rude payment issue ...      1  \n",
       "\n",
       "[2008 rows x 36 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = df\n",
    "X = resampled_df['lemmatized_comment']\n",
    "y = resampled_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(X,y, \n",
    "                                                               X.index, test_size=0.25, \n",
    "                                                               random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the 1779 comment is represented by 1994 features (TF-IDF score of unigrams and bigrams)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                        ngram_range=(1, 2))\n",
    "\n",
    "#print(df.comment3lemmatize)\n",
    "# We transform each complaint into a vector\n",
    "fitted_vectorizer = tfidf.fit(X_train)\n",
    "\n",
    "features = fitted_vectorizer.transform(X_train)\n",
    "\n",
    "labels = y_train\n",
    "print(\"Each of the %d comment is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "selector = SelectKBest(chi2,250)\n",
    "fitted_selector = selector.fit(features,y_train)\n",
    "features_new = fitted_selector.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fitted_selector.get_support() #list of booleans\n",
    "new_features_names = [] # The list of your K best features\n",
    "feature_names= tfidf.get_feature_names()\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        new_features_names.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.835 params {'n_estimators': 560, 'max_depth': 2, 'min_child_weight': 4, 'learning_rate': 0.33730459250060224, 'gamma': 1.4506989750818944, 'colsample_bytree': 0.6844639545892011, 'subsample': 0.7899429261573497, 'colsample_bylevel': 0.43539866858425197}\n",
      "AUC 0.854 params {'n_estimators': 260, 'max_depth': 9, 'min_child_weight': 1, 'learning_rate': 0.2775651937347629, 'gamma': 0.7417703183023474, 'colsample_bytree': 0.779467048644354, 'subsample': 0.716929483914224, 'colsample_bylevel': 0.588329974455629}\n",
      "AUC 0.854 params {'n_estimators': 460, 'max_depth': 5, 'min_child_weight': 2, 'learning_rate': 0.21259318544940017, 'gamma': 1.4813809945882346, 'colsample_bytree': 0.7836009951570224, 'subsample': 0.8802655641681099, 'colsample_bylevel': 0.7633374505535013}\n",
      "AUC 0.814 params {'n_estimators': 510, 'max_depth': 3, 'min_child_weight': 6, 'learning_rate': 0.2631197051414458, 'gamma': 0.9286646454071584, 'colsample_bytree': 0.4899990568264899, 'subsample': 0.7745487980903359, 'colsample_bylevel': 0.6209722461007045}\n",
      "AUC 0.830 params {'n_estimators': 610, 'max_depth': 12, 'min_child_weight': 3, 'learning_rate': 0.36868001296542247, 'gamma': 1.3056199501378594, 'colsample_bytree': 0.89072554896206, 'subsample': 0.8073699798506913, 'colsample_bylevel': 0.3807494291226782}\n",
      "AUC 0.824 params {'n_estimators': 60, 'max_depth': 14, 'min_child_weight': 5, 'learning_rate': 0.33101603706139693, 'gamma': 1.4656152228610397, 'colsample_bytree': 0.5029136576236284, 'subsample': 0.733291854202578, 'colsample_bylevel': 0.6027395158838821}\n",
      "AUC 0.851 params {'n_estimators': 860, 'max_depth': 14, 'min_child_weight': 3, 'learning_rate': 0.010299165134639507, 'gamma': 0.6891762018929272, 'colsample_bytree': 0.35254449244600605, 'subsample': 0.8889212479675938, 'colsample_bylevel': 0.6613383359013612}\n",
      "AUC 0.846 params {'n_estimators': 960, 'max_depth': 6, 'min_child_weight': 2, 'learning_rate': 0.39544838663117, 'gamma': 0.6973236046586881, 'colsample_bytree': 0.3744839768996446, 'subsample': 0.9303244783190284, 'colsample_bylevel': 0.7359166326467013}\n",
      "AUC 0.849 params {'n_estimators': 260, 'max_depth': 12, 'min_child_weight': 2, 'learning_rate': 0.1803315970584746, 'gamma': 0.8113736061372243, 'colsample_bytree': 0.8319489918497351, 'subsample': 0.9050505588509851, 'colsample_bylevel': 0.42872332791271756}\n",
      "AUC 0.808 params {'n_estimators': 210, 'max_depth': 1, 'min_child_weight': 6, 'learning_rate': 0.4489456277614735, 'gamma': 0.6338081450568659, 'colsample_bytree': 0.48190751945280075, 'subsample': 0.7331804916224143, 'colsample_bylevel': 0.44339651364174665}\n",
      "AUC 0.824 params {'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 6, 'learning_rate': 0.41491730715351494, 'gamma': 1.2114571982415556, 'colsample_bytree': 0.8482250802553042, 'subsample': 0.9197517849377883, 'colsample_bylevel': 0.4756956996362755}\n",
      "AUC 0.851 params {'n_estimators': 60, 'max_depth': 8, 'min_child_weight': 2, 'learning_rate': 0.06936673747256294, 'gamma': 0.9242978896088265, 'colsample_bytree': 0.8812273519111042, 'subsample': 0.8396816919170428, 'colsample_bylevel': 0.6059974844524982}\n",
      "AUC 0.825 params {'n_estimators': 760, 'max_depth': 3, 'min_child_weight': 6, 'learning_rate': 0.0922636117557847, 'gamma': 1.1391996258296426, 'colsample_bytree': 0.5863970201779103, 'subsample': 0.8502359192613503, 'colsample_bylevel': 0.3052886624091075}\n",
      "AUC 0.818 params {'n_estimators': 1060, 'max_depth': 13, 'min_child_weight': 4, 'learning_rate': 0.2539599202545313, 'gamma': 0.6967517904777746, 'colsample_bytree': 0.8238524642598073, 'subsample': 0.71822822525269, 'colsample_bylevel': 0.43333595748470505}\n",
      "AUC 0.836 params {'n_estimators': 10, 'max_depth': 13, 'min_child_weight': 4, 'learning_rate': 0.41614489763491475, 'gamma': 0.3505464377844427, 'colsample_bytree': 0.8352927053719539, 'subsample': 0.7916539873854442, 'colsample_bylevel': 0.33513941018453036}\n",
      "AUC 0.825 params {'n_estimators': 410, 'max_depth': 13, 'min_child_weight': 4, 'learning_rate': 0.20388914933298374, 'gamma': 0.5909178553362786, 'colsample_bytree': 0.635420062756409, 'subsample': 0.7970207828998387, 'colsample_bylevel': 0.7129448590865972}\n",
      "AUC 0.818 params {'n_estimators': 810, 'max_depth': 11, 'min_child_weight': 6, 'learning_rate': 0.37872050191556206, 'gamma': 0.8554119017167056, 'colsample_bytree': 0.48429972970493074, 'subsample': 0.9612463758055368, 'colsample_bylevel': 0.7323050977452225}\n",
      "AUC 0.841 params {'n_estimators': 210, 'max_depth': 3, 'min_child_weight': 3, 'learning_rate': 0.03136618490644272, 'gamma': 0.1375568041911628, 'colsample_bytree': 0.5338062855085517, 'subsample': 0.7369606833366608, 'colsample_bylevel': 0.6557088826985447}\n",
      "AUC 0.862 params {'n_estimators': 510, 'max_depth': 14, 'min_child_weight': 1, 'learning_rate': 0.012860842191751876, 'gamma': 1.2093986961318934, 'colsample_bytree': 0.3955931523436132, 'subsample': 0.830885646032338, 'colsample_bylevel': 0.6550615986115176}\n",
      "AUC 0.846 params {'n_estimators': 910, 'max_depth': 15, 'min_child_weight': 1, 'learning_rate': 0.4886271060963942, 'gamma': 1.0294711913518648, 'colsample_bytree': 0.6020328712554242, 'subsample': 0.9608502841907018, 'colsample_bylevel': 0.6025647607960236}\n",
      "AUC 0.851 params {'n_estimators': 360, 'max_depth': 9, 'min_child_weight': 1, 'learning_rate': 0.14383095604999183, 'gamma': 0.46126503589435175, 'colsample_bytree': 0.7312263756879469, 'subsample': 0.8498162929170536, 'colsample_bylevel': 0.5181166592753059}\n",
      "AUC 0.814 params {'n_estimators': 260, 'max_depth': 7, 'min_child_weight': 7, 'learning_rate': 0.2845368093486603, 'gamma': 1.068478886848628, 'colsample_bytree': 0.3253503489499316, 'subsample': 0.7661144603628097, 'colsample_bylevel': 0.5439932180724882}\n",
      "AUC 0.858 params {'n_estimators': 310, 'max_depth': 9, 'min_child_weight': 1, 'learning_rate': 0.13764924312420956, 'gamma': 1.3462594274546065, 'colsample_bytree': 0.4200638280659848, 'subsample': 0.9949495397432948, 'colsample_bylevel': 0.797766978317756}\n",
      "AUC 0.856 params {'n_estimators': 310, 'max_depth': 4, 'min_child_weight': 1, 'learning_rate': 0.10790832944624443, 'gamma': 1.3166743508316558, 'colsample_bytree': 0.41208883633112825, 'subsample': 0.9992036876764453, 'colsample_bylevel': 0.7848868250492137}\n",
      "AUC 0.851 params {'n_estimators': 510, 'max_depth': 14, 'min_child_weight': 1, 'learning_rate': 0.1311940119862961, 'gamma': 1.3306832041142285, 'colsample_bytree': 0.41446041408384254, 'subsample': 0.825478114144756, 'colsample_bylevel': 0.670911667431472}\n",
      "AUC 0.837 params {'n_estimators': 310, 'max_depth': 10, 'min_child_weight': 5, 'learning_rate': 0.04566039882312725, 'gamma': 1.220812782838526, 'colsample_bytree': 0.32147362221422715, 'subsample': 0.8673426791887803, 'colsample_bylevel': 0.7891189064402071}\n",
      "AUC 0.854 params {'n_estimators': 1010, 'max_depth': 9, 'min_child_weight': 1, 'learning_rate': 0.16216706144578114, 'gamma': 1.3917298212973699, 'colsample_bytree': 0.4271361707134735, 'subsample': 0.9835587515667955, 'colsample_bylevel': 0.7025927530809453}\n",
      "AUC 0.816 params {'n_estimators': 660, 'max_depth': 15, 'min_child_weight': 7, 'learning_rate': 0.0686907329093566, 'gamma': 1.0326686136357695, 'colsample_bytree': 0.5398098459875662, 'subsample': 0.9504869059541035, 'colsample_bylevel': 0.7953225821073029}\n",
      "AUC 0.850 params {'n_estimators': 160, 'max_depth': 14, 'min_child_weight': 1, 'learning_rate': 0.013378441137027188, 'gamma': 1.2190258591904635, 'colsample_bytree': 0.43982369940484956, 'subsample': 0.8143089620940831, 'colsample_bylevel': 0.5488420832364711}\n",
      "AUC 0.852 params {'n_estimators': 110, 'max_depth': 4, 'min_child_weight': 1, 'learning_rate': 0.10990296215087482, 'gamma': 1.4984685414134722, 'colsample_bytree': 0.3577696440801986, 'subsample': 0.7681516771429773, 'colsample_bylevel': 0.688293082356524}\n",
      "AUC 0.858 params {'n_estimators': 560, 'max_depth': 9, 'min_child_weight': 1, 'learning_rate': 0.22954065538979113, 'gamma': 1.133695151229978, 'colsample_bytree': 0.6470033365416221, 'subsample': 0.8697995258798219, 'colsample_bylevel': 0.7539787499952538}\n",
      "AUC 0.834 params {'n_estimators': 310, 'max_depth': 5, 'min_child_weight': 5, 'learning_rate': 0.314123329821159, 'gamma': 1.4086384792470645, 'colsample_bytree': 0.30468751101245994, 'subsample': 0.9133050154626717, 'colsample_bylevel': 0.5061492150045382}\n",
      "AUC 0.819 params {'n_estimators': 710, 'max_depth': 6, 'min_child_weight': 7, 'learning_rate': 0.050750651858513504, 'gamma': 1.4992885287697084, 'colsample_bytree': 0.44498565748946384, 'subsample': 0.8927950439326153, 'colsample_bylevel': 0.6421615990313718}\n",
      "AUC 0.854 params {'n_estimators': 510, 'max_depth': 1, 'min_child_weight': 1, 'learning_rate': 0.17903512440225222, 'gamma': 0.9820337489520625, 'colsample_bytree': 0.38121526764210656, 'subsample': 0.8288458742958454, 'colsample_bylevel': 0.5696231270026192}\n",
      "AUC 0.855 params {'n_estimators': 460, 'max_depth': 10, 'min_child_weight': 1, 'learning_rate': 0.0903788533556314, 'gamma': 1.1236929094344443, 'colsample_bytree': 0.6957546633422769, 'subsample': 0.9361728519763471, 'colsample_bylevel': 0.771279619819089}\n",
      "AUC 0.842 params {'n_estimators': 510, 'max_depth': 7, 'min_child_weight': 3, 'learning_rate': 0.1311639282912454, 'gamma': 1.3814663865606724, 'colsample_bytree': 0.543234003235104, 'subsample': 0.9958009316309306, 'colsample_bylevel': 0.631890398147923}\n",
      "AUC 0.813 params {'n_estimators': 960, 'max_depth': 11, 'min_child_weight': 5, 'learning_rate': 0.21878710836748427, 'gamma': 1.264209530780716, 'colsample_bytree': 0.4652601723204612, 'subsample': 0.7519992003210694, 'colsample_bylevel': 0.5790831131494256}\n",
      "AUC 0.849 params {'n_estimators': 610, 'max_depth': 2, 'min_child_weight': 1, 'learning_rate': 0.02919955647585606, 'gamma': 0.9313705568900329, 'colsample_bytree': 0.39084597224566126, 'subsample': 0.7014466888233106, 'colsample_bylevel': 0.7362451395115586}\n",
      "AUC 0.843 params {'n_estimators': 860, 'max_depth': 8, 'min_child_weight': 2, 'learning_rate': 0.18182324119590507, 'gamma': 0.7856919696708824, 'colsample_bytree': 0.3005307531799642, 'subsample': 0.7825200883176183, 'colsample_bylevel': 0.3912713569817451}\n",
      "AUC 0.847 params {'n_estimators': 310, 'max_depth': 14, 'min_child_weight': 3, 'learning_rate': 0.06956413532491278, 'gamma': 1.4455330931551897, 'colsample_bytree': 0.33912028498049007, 'subsample': 0.8760838447745247, 'colsample_bylevel': 0.6834201633267972}\n",
      "AUC 0.805 params {'n_estimators': 1060, 'max_depth': 12, 'min_child_weight': 7, 'learning_rate': 0.3014297832485517, 'gamma': 1.1689875464277844, 'colsample_bytree': 0.5295583470085977, 'subsample': 0.8982957793674676, 'colsample_bylevel': 0.7535863490084668}\n",
      "AUC 0.815 params {'n_estimators': 760, 'max_depth': 9, 'min_child_weight': 4, 'learning_rate': 0.24307295409272905, 'gamma': 0.18076953230736437, 'colsample_bytree': 0.5745692787843092, 'subsample': 0.8571812776422145, 'colsample_bylevel': 0.7111703932570043}\n",
      "AUC 0.861 params {'n_estimators': 410, 'max_depth': 5, 'min_child_weight': 1, 'learning_rate': 0.15463823077078506, 'gamma': 0.5283105975204466, 'colsample_bytree': 0.4639343061315283, 'subsample': 0.8008701960311041, 'colsample_bylevel': 0.4745334527028004}\n",
      "AUC 0.843 params {'n_estimators': 360, 'max_depth': 5, 'min_child_weight': 2, 'learning_rate': 0.3454543869311075, 'gamma': 0.3286279410741838, 'colsample_bytree': 0.5100168487030604, 'subsample': 0.814762164374651, 'colsample_bylevel': 0.4686690475760737}\n",
      "AUC 0.813 params {'n_estimators': 410, 'max_depth': 5, 'min_child_weight': 6, 'learning_rate': 0.20179186319276127, 'gamma': 0.5556260256002482, 'colsample_bytree': 0.46110687106890247, 'subsample': 0.8021028421268547, 'colsample_bylevel': 0.39016975458351283}\n",
      "AUC 0.825 params {'n_estimators': 410, 'max_depth': 5, 'min_child_weight': 5, 'learning_rate': 0.017048812586392625, 'gamma': 0.26959986770586786, 'colsample_bytree': 0.5641123497004555, 'subsample': 0.7457919334475563, 'colsample_bylevel': 0.3566014160389883}\n",
      "AUC 0.849 params {'n_estimators': 10, 'max_depth': 14, 'min_child_weight': 1, 'learning_rate': 0.2737378357224874, 'gamma': 0.4865318491134286, 'colsample_bytree': 0.6062745660253197, 'subsample': 0.7112287794662144, 'colsample_bylevel': 0.5131256015476734}\n",
      "AUC 0.829 params {'n_estimators': 410, 'max_depth': 6, 'min_child_weight': 4, 'learning_rate': 0.16483535730526036, 'gamma': 0.4435390405804237, 'colsample_bytree': 0.5082063301200265, 'subsample': 0.7824269326102622, 'colsample_bylevel': 0.4638396661444554}\n",
      "AUC 0.841 params {'n_estimators': 810, 'max_depth': 1, 'min_child_weight': 3, 'learning_rate': 0.3342242277097893, 'gamma': 0.8572748288112224, 'colsample_bytree': 0.7474688140221699, 'subsample': 0.8401565019437836, 'colsample_bylevel': 0.4250468629135093}\n",
      "AUC 0.829 params {'n_estimators': 910, 'max_depth': 8, 'min_child_weight': 2, 'learning_rate': 0.4984066882452279, 'gamma': 0.7222661573899298, 'colsample_bytree': 0.6518160684487236, 'subsample': 0.7620442325802224, 'colsample_bylevel': 0.3209337352707642}\n",
      "AUC 0.820 params {'n_estimators': 110, 'max_depth': 2, 'min_child_weight': 6, 'learning_rate': 0.10711864587892976, 'gamma': 0.6410626636785315, 'colsample_bytree': 0.3545118495966544, 'subsample': 0.8307302243158861, 'colsample_bylevel': 0.48949644821410887}\n",
      "AUC 0.854 params {'n_estimators': 160, 'max_depth': 3, 'min_child_weight': 1, 'learning_rate': 0.457513209905519, 'gamma': 0.38088090422213483, 'colsample_bytree': 0.39991092930417727, 'subsample': 0.813233415913074, 'colsample_bylevel': 0.4066859686438138}\n",
      "AUC 0.851 params {'n_estimators': 660, 'max_depth': 12, 'min_child_weight': 1, 'learning_rate': 0.08538999271037237, 'gamma': 0.22772223464078012, 'colsample_bytree': 0.6843039800721264, 'subsample': 0.789278592385833, 'colsample_bylevel': 0.6137955269184523}\n",
      "AUC 0.824 params {'n_estimators': 1010, 'max_depth': 5, 'min_child_weight': 4, 'learning_rate': 0.35990651324452727, 'gamma': 0.5135048003484414, 'colsample_bytree': 0.4699853361145715, 'subsample': 0.7287097467990015, 'colsample_bylevel': 0.5641913506898566}\n",
      "AUC 0.814 params {'n_estimators': 510, 'max_depth': 11, 'min_child_weight': 7, 'learning_rate': 0.04946648489041312, 'gamma': 0.10384416471182367, 'colsample_bytree': 0.4884401372233669, 'subsample': 0.8598384954007838, 'colsample_bylevel': 0.5383921443664744}\n",
      "AUC 0.815 params {'n_estimators': 210, 'max_depth': 13, 'min_child_weight': 6, 'learning_rate': 0.2531873043428574, 'gamma': 0.6634718790902013, 'colsample_bytree': 0.6219598863370519, 'subsample': 0.881938319077212, 'colsample_bylevel': 0.5884277801444457}\n",
      "AUC 0.857 params {'n_estimators': 710, 'max_depth': 15, 'min_child_weight': 1, 'learning_rate': 0.19072996974865253, 'gamma': 0.7823774393930949, 'colsample_bytree': 0.37650518491356133, 'subsample': 0.7767848006835485, 'colsample_bylevel': 0.4443763004332981}\n",
      "AUC 0.846 params {'n_estimators': 60, 'max_depth': 14, 'min_child_weight': 3, 'learning_rate': 0.16453583900598223, 'gamma': 0.6018295298674895, 'colsample_bytree': 0.7776590886130855, 'subsample': 0.926429200986723, 'colsample_bylevel': 0.36840455277091044}\n",
      "AUC 0.820 params {'n_estimators': 560, 'max_depth': 7, 'min_child_weight': 5, 'learning_rate': 0.1494243998031192, 'gamma': 0.3997411516577657, 'colsample_bytree': 0.5581463079050715, 'subsample': 0.843870152259914, 'colsample_bylevel': 0.532123702439336}\n",
      "AUC 0.841 params {'n_estimators': 260, 'max_depth': 14, 'min_child_weight': 2, 'learning_rate': 0.39793886679337975, 'gamma': 0.8332569677627018, 'colsample_bytree': 0.31972522295930417, 'subsample': 0.7519891115236192, 'colsample_bylevel': 0.6519879058684744}\n",
      "AUC 0.857 params {'n_estimators': 610, 'max_depth': 4, 'min_child_weight': 1, 'learning_rate': 0.23491148079293475, 'gamma': 0.9218400968530323, 'colsample_bytree': 0.43629961679348506, 'subsample': 0.9052832548622921, 'colsample_bylevel': 0.49841431628679733}\n",
      "AUC 0.854 params {'n_estimators': 960, 'max_depth': 10, 'min_child_weight': 1, 'learning_rate': 0.11855488994833929, 'gamma': 0.5590967352810787, 'colsample_bytree': 0.8679727414143801, 'subsample': 0.7958257200324831, 'colsample_bylevel': 0.34440077559691584}\n",
      "AUC 0.813 params {'n_estimators': 460, 'max_depth': 3, 'min_child_weight': 7, 'learning_rate': 0.07135849694287971, 'gamma': 0.2946067451551243, 'colsample_bytree': 0.586872942158295, 'subsample': 0.8223342260197454, 'colsample_bylevel': 0.5944421893249594}\n",
      "AUC 0.824 params {'n_estimators': 860, 'max_depth': 5, 'min_child_weight': 4, 'learning_rate': 0.2848145667691749, 'gamma': 1.0546236321105986, 'colsample_bytree': 0.36409322667382427, 'subsample': 0.7212249466277432, 'colsample_bylevel': 0.6304111973762143}\n",
      "AUC 0.862 params {'n_estimators': 410, 'max_depth': 13, 'min_child_weight': 1, 'learning_rate': 0.03205123295222909, 'gamma': 0.9680780167072784, 'colsample_bytree': 0.522182979302659, 'subsample': 0.8051552882799482, 'colsample_bylevel': 0.3016739640441922}\n",
      "AUC 0.860 params {'n_estimators': 410, 'max_depth': 13, 'min_child_weight': 1, 'learning_rate': 0.03455899675617338, 'gamma': 1.261693288988982, 'colsample_bytree': 0.5124421409731034, 'subsample': 0.8015647173546342, 'colsample_bylevel': 0.3070608314369334}\n",
      "AUC 0.859 params {'n_estimators': 410, 'max_depth': 13, 'min_child_weight': 1, 'learning_rate': 0.018232825639704534, 'gamma': 0.9821174970924953, 'colsample_bytree': 0.40277484620154264, 'subsample': 0.8324515434804116, 'colsample_bylevel': 0.673093696463957}\n",
      "AUC 0.856 params {'n_estimators': 410, 'max_depth': 13, 'min_child_weight': 1, 'learning_rate': 0.062062676591254834, 'gamma': 0.8928975335643976, 'colsample_bytree': 0.4521301958179317, 'subsample': 0.8502930340079572, 'colsample_bylevel': 0.5247344456254943}\n",
      "AUC 0.864 params {'n_estimators': 510, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.09520194824175505, 'gamma': 1.1020474587964464, 'colsample_bytree': 0.4908567846524142, 'subsample': 0.7622694310500184, 'colsample_bylevel': 0.5593257295147386}\n",
      "AUC 0.862 params {'n_estimators': 510, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.03679760857730901, 'gamma': 1.0897644249027076, 'colsample_bytree': 0.5244548636892243, 'subsample': 0.7432752131863567, 'colsample_bylevel': 0.5558136346200175}\n",
      "AUC 0.856 params {'n_estimators': 510, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.08866994268695294, 'gamma': 1.1246071111044882, 'colsample_bytree': 0.5272838434875433, 'subsample': 0.7423862189022699, 'colsample_bylevel': 0.5587811017663936}\n",
      "AUC 0.863 params {'n_estimators': 510, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.037348267080016526, 'gamma': 1.1807702371131015, 'colsample_bytree': 0.6739562324371945, 'subsample': 0.7578708994019291, 'colsample_bylevel': 0.617843451112962}\n",
      "AUC 0.809 params {'n_estimators': 510, 'max_depth': 6, 'min_child_weight': 6, 'learning_rate': 0.10109258531237869, 'gamma': 0.9965917118770317, 'colsample_bytree': 0.6791660890813773, 'subsample': 0.7065868737879835, 'colsample_bylevel': 0.6232151107441068}\n",
      "AUC 0.859 params {'n_estimators': 1060, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.12351944312175364, 'gamma': 1.2934736425199813, 'colsample_bytree': 0.8006924537369671, 'subsample': 0.7614371323139492, 'colsample_bylevel': 0.5737216782798021}\n",
      "AUC 0.822 params {'n_estimators': 760, 'max_depth': 6, 'min_child_weight': 5, 'learning_rate': 0.05240416442071247, 'gamma': 1.1702340575276222, 'colsample_bytree': 0.7191630047623756, 'subsample': 0.7286821231248841, 'colsample_bylevel': 0.4496618062940938}\n",
      "AUC 0.803 params {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 3, 'learning_rate': 0.08051552909301983, 'gamma': 1.4354586510790206, 'colsample_bytree': 0.6220416693328288, 'subsample': 0.770235888383034, 'colsample_bylevel': 0.6010125277205824}\n",
      "AUC 0.721 params {'n_estimators': 360, 'max_depth': 1, 'min_child_weight': 1, 'learning_rate': 0.011461287101133508, 'gamma': 1.1820743294364486, 'colsample_bytree': 0.7162508239688776, 'subsample': 0.7185050775080571, 'colsample_bylevel': 0.725449017654036}\n",
      "AUC 0.854 params {'n_estimators': 810, 'max_depth': 6, 'min_child_weight': 2, 'learning_rate': 0.0240170468233197, 'gamma': 1.3633402631614813, 'colsample_bytree': 0.6733817817505651, 'subsample': 0.7555231601762764, 'colsample_bylevel': 0.6967356915867771}\n",
      "AUC 0.816 params {'n_estimators': 910, 'max_depth': 13, 'min_child_weight': 7, 'learning_rate': 0.04064286388817723, 'gamma': 1.0867150715609672, 'colsample_bytree': 0.7491054439640137, 'subsample': 0.7849175025455529, 'colsample_bylevel': 0.41547718821830293}\n",
      "AUC 0.854 params {'n_estimators': 510, 'max_depth': 15, 'min_child_weight': 1, 'learning_rate': 0.058147635989200724, 'gamma': 0.956868912388477, 'colsample_bytree': 0.5497778715367081, 'subsample': 0.7740821897719298, 'colsample_bylevel': 0.5819577581993282}\n",
      "AUC 0.837 params {'n_estimators': 210, 'max_depth': 2, 'min_child_weight': 4, 'learning_rate': 0.11394169131174096, 'gamma': 0.7397655365261194, 'colsample_bytree': 0.6600536592148408, 'subsample': 0.7368605306604983, 'colsample_bylevel': 0.492541191643481}\n",
      "AUC 0.858 params {'n_estimators': 1010, 'max_depth': 8, 'min_child_weight': 1, 'learning_rate': 0.09802099342763756, 'gamma': 1.2527270294548378, 'colsample_bytree': 0.591629203971744, 'subsample': 0.7037188421497466, 'colsample_bylevel': 0.6406793920908372}\n",
      "AUC 0.827 params {'n_estimators': 160, 'max_depth': 12, 'min_child_weight': 5, 'learning_rate': 0.13372399078663222, 'gamma': 0.903586454780358, 'colsample_bytree': 0.7035493891949767, 'subsample': 0.8171043023695339, 'colsample_bylevel': 0.48317914476820056}\n",
      "AUC 0.819 params {'n_estimators': 110, 'max_depth': 4, 'min_child_weight': 6, 'learning_rate': 0.07745361919214218, 'gamma': 1.0217758668455246, 'colsample_bytree': 0.6057198953320899, 'subsample': 0.7929580009174934, 'colsample_bylevel': 0.6100906361211553}\n",
      "AUC 0.853 params {'n_estimators': 660, 'max_depth': 11, 'min_child_weight': 1, 'learning_rate': 0.22179220812397732, 'gamma': 0.8655016476987406, 'colsample_bytree': 0.632480158420843, 'subsample': 0.7593919668506233, 'colsample_bylevel': 0.4556877263079978}\n",
      "AUC 0.844 params {'n_estimators': 60, 'max_depth': 10, 'min_child_weight': 3, 'learning_rate': 0.20533890142750807, 'gamma': 1.311039198367631, 'colsample_bytree': 0.4900254142106785, 'subsample': 0.8063788727456795, 'colsample_bylevel': 0.6740396286371294}\n",
      "AUC 0.849 params {'n_estimators': 560, 'max_depth': 7, 'min_child_weight': 2, 'learning_rate': 0.18776959607924482, 'gamma': 1.198972240720643, 'colsample_bytree': 0.5722807453926831, 'subsample': 0.7791316562990223, 'colsample_bylevel': 0.5455339967126863}\n",
      "AUC 0.852 params {'n_estimators': 710, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.17293371288864845, 'gamma': 0.9556008004822243, 'colsample_bytree': 0.7722532462755515, 'subsample': 0.7701049381085646, 'colsample_bylevel': 0.5050579924718885}\n",
      "AUC 0.814 params {'n_estimators': 260, 'max_depth': 13, 'min_child_weight': 7, 'learning_rate': 0.140962700372503, 'gamma': 0.7850185536229997, 'colsample_bytree': 0.42280969251819983, 'subsample': 0.7273924035851661, 'colsample_bylevel': 0.6647658580529507}\n",
      "AUC 0.860 params {'n_estimators': 510, 'max_depth': 9, 'min_child_weight': 1, 'learning_rate': 0.02846101371348186, 'gamma': 1.4694120430341697, 'colsample_bytree': 0.8153762515426886, 'subsample': 0.7489611151733684, 'colsample_bylevel': 0.6486305813795686}\n",
      "AUC 0.841 params {'n_estimators': 960, 'max_depth': 3, 'min_child_weight': 4, 'learning_rate': 0.06385921076492812, 'gamma': 1.2340023792354649, 'colsample_bytree': 0.4985425139276169, 'subsample': 0.8090199719234998, 'colsample_bylevel': 0.5214820072803745}\n",
      "AUC 0.852 params {'n_estimators': 460, 'max_depth': 6, 'min_child_weight': 1, 'learning_rate': 0.010605379602465225, 'gamma': 0.8180804299013773, 'colsample_bytree': 0.4746938804205252, 'subsample': 0.7133444719400863, 'colsample_bylevel': 0.7125402420046805}\n",
      "AUC 0.833 params {'n_estimators': 1060, 'max_depth': 1, 'min_child_weight': 5, 'learning_rate': 0.15522649716066966, 'gamma': 1.1509846170068176, 'colsample_bytree': 0.6145620647675705, 'subsample': 0.788393166199556, 'colsample_bylevel': 0.7678853760045415}\n",
      "AUC 0.840 params {'n_estimators': 610, 'max_depth': 2, 'min_child_weight': 3, 'learning_rate': 0.3199881014305368, 'gamma': 1.0934602449277637, 'colsample_bytree': 0.6679324570467493, 'subsample': 0.8211135049691227, 'colsample_bylevel': 0.6902528084656202}\n",
      "AUC 0.825 params {'n_estimators': 510, 'max_depth': 15, 'min_child_weight': 6, 'learning_rate': 0.0997533894459238, 'gamma': 1.4077006799747254, 'colsample_bytree': 0.34078845469493396, 'subsample': 0.8376573831142602, 'colsample_bylevel': 0.5881436472940036}\n",
      "AUC 0.851 params {'n_estimators': 760, 'max_depth': 8, 'min_child_weight': 1, 'learning_rate': 0.44808408794550214, 'gamma': 1.0050447373358695, 'colsample_bytree': 0.6338277771003654, 'subsample': 0.863858285306527, 'colsample_bylevel': 0.43320215409475826}\n",
      "AUC 0.852 params {'n_estimators': 860, 'max_depth': 12, 'min_child_weight': 2, 'learning_rate': 0.0431345881827573, 'gamma': 1.2912653885962497, 'colsample_bytree': 0.6475911587509255, 'subsample': 0.7335564623998743, 'colsample_bylevel': 0.6192516175441813}\n",
      "AUC 0.833 params {'n_estimators': 10, 'max_depth': 11, 'min_child_weight': 1, 'learning_rate': 0.12540909837548236, 'gamma': 1.0547280099561853, 'colsample_bytree': 0.5799129709474244, 'subsample': 0.8798433143233805, 'colsample_bylevel': 0.5325123720773334}\n",
      "AUC 0.804 params {'n_estimators': 360, 'max_depth': 13, 'min_child_weight': 7, 'learning_rate': 0.2967873526499953, 'gamma': 0.6960863604883245, 'colsample_bytree': 0.7563376248058998, 'subsample': 0.8525613075925489, 'colsample_bylevel': 0.40133486088850645}\n",
      "AUC 0.857 params {'n_estimators': 310, 'max_depth': 7, 'min_child_weight': 1, 'learning_rate': 0.07612266685427277, 'gamma': 1.3473639411977059, 'colsample_bytree': 0.5594306992923547, 'subsample': 0.7659313503346602, 'colsample_bylevel': 0.7440332836299582}\n",
      "100%|██████████| 100/100 [03:10<00:00,  1.90s/trial, best loss: -0.8638213120891949]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparamete Tuning\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score\n",
    "from hyperopt import hp, tpe\n",
    "import xgboost as xgb\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "def objective(params):\n",
    "   \n",
    "    params = {'n_estimators': int(params['n_estimators']),\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_child_weight': int(params['min_child_weight']),\n",
    "              'learning_rate' : float(params['learning_rate']),\n",
    "              'gamma': float(params['gamma']),\n",
    "              'colsample_bytree': float(params['colsample_bytree']),\n",
    "              'subsample': float(params['subsample']),\n",
    "              'colsample_bylevel': float(params['colsample_bylevel'])\n",
    "#               ,'class_weight':str(params['class_weight'])\n",
    "             }\n",
    "   \n",
    "    clf = xgb.XGBClassifier(random_state=42, **params)\n",
    "    score = cross_val_score(clf,features_new,labels, scoring=auc_scorer, cv=StratifiedKFold(n_splits=5)).mean()\n",
    "    print(\"AUC {:.3f} params {}\".format(score, params))\n",
    "    return -score\n",
    "\n",
    "space = {\n",
    "    'learning_rate':    hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(1, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'gamma' : hp.uniform('gamma', 0.1, 1.5),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 0.9),\n",
    "    'subsample':        hp.uniform('subsample', 0.7, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.3, 0.8),\n",
    "    'n_estimators':     hp.choice('n_estimators', np.arange(10, 1100, 50, dtype=int)),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100)\n",
    "for i in best.keys():\n",
    "    best[i] = int(best[i])\n",
    "\n",
    "best_model = xgb.XGBClassifier(random_state=42, **best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.30, shuffle=True)\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train.lemmatized_comment)\n",
    "vectorizer.fit(test.lemmatized_comment)\n",
    "x_train = vectorizer.transform(train.lemmatized_comment)\n",
    "y_train = train[['Class']]\n",
    "x_test = vectorizer.transform(test.lemmatized_comment)\n",
    "y_test = test[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib64/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.5593257295147386,\n",
       "              colsample_bytree=0.4908567846524142, gamma=1.1020474587964464,\n",
       "              learning_rate=0.09520194824175505, max_delta_step=0, max_depth=80,\n",
       "              min_child_weight=1, missing=None, n_estimators=510, n_jobs=1,\n",
       "              nthread=None, num_class=2, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1.7545605306799337, seed=None, silent=True,\n",
       "              subsample=0.7622694310500184)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "\n",
    "xgb_model =  xgb.XGBClassifier(objective='multi:softprob', num_class=2, n_estimators= 510, max_depth= 80, min_child_weight= 1, learning_rate= 0.09520194824175505, gamma= 1.1020474587964464,\n",
    "                                      colsample_bytree= 0.4908567846524142, subsample= 0.7622694310500184, colsample_bylevel= 0.5593257295147386,\n",
    "                                          scale_pos_weight=train.Class[train.Class==0].count()/train.Class[train.Class==1].count())\n",
    "            \n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.76%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       457\n",
      "           1       0.89      0.79      0.83       255\n",
      "\n",
      "    accuracy                           0.89       712\n",
      "   macro avg       0.89      0.87      0.87       712\n",
      "weighted avg       0.89      0.89      0.89       712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Booking.com reviews\n",
    "\n",
    "df1 = pd.read_csv('Hotel_Reviews.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive = df1[['Positive_Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative = df1[['Negative_Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative = df1_negative[df1_negative.Negative_Review!='No Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative = df1_negative[df1_negative.Negative_Review!='Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Backyard of the hotel is total mess shouldn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515731</th>\n",
       "      <td>No parking Public parking garage is 15 Euro p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387848 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Negative_Review\n",
       "0        I am so angry that i made this post available...\n",
       "2        Rooms are nice but for elderly a bit difficul...\n",
       "3        My room was dirty and I was afraid to walk ba...\n",
       "4        You When I booked with your company on line y...\n",
       "5        Backyard of the hotel is total mess shouldn t...\n",
       "...                                                   ...\n",
       "515731   No parking Public parking garage is 15 Euro p...\n",
       "515733   no trolly or staff to help you take the lugga...\n",
       "515734           The hotel looks like 3 but surely not 4 \n",
       "515735   The ac was useless It was a hot week in vienn...\n",
       "515737       I was in 3rd floor It didn t work Free Wife \n",
       "\n",
       "[387848 rows x 1 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive = df1_positive[df1_positive.Positive_Review!='No Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive = df1_positive[df1_positive.Positive_Review!='Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515732</th>\n",
       "      <td>helpful staff allowed me to check in early as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>Breakfast was ok and we got earlier check in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>The rooms are enormous and really comfortable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>staff was very kind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479792 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Positive_Review\n",
       "0        Only the park outside of the hotel was beauti...\n",
       "1        No real complaints the hotel was great great ...\n",
       "2        Location was good and staff were ok It is cut...\n",
       "3        Great location in nice surroundings the bar a...\n",
       "4         Amazing location and building Romantic setting \n",
       "...                                                   ...\n",
       "515732   helpful staff allowed me to check in early as...\n",
       "515733                                           location\n",
       "515734      Breakfast was ok and we got earlier check in \n",
       "515736   The rooms are enormous and really comfortable...\n",
       "515737                               staff was very kind \n",
       "\n",
       "[479792 rows x 1 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive = df1_positive[df1_positive['Positive_Review'].apply(lambda x: len(x.split(' ')) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1_positive['Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive.columns = ['review', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative =  df1_negative[df1_negative['Negative_Review'].apply(lambda x: len(x.split(' ')) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1_negative['Class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative.columns = ['review', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Backyard of the hotel is total mess shouldn t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515731</th>\n",
       "      <td>No parking Public parking garage is 15 Euro p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345057 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  Class\n",
       "0        I am so angry that i made this post available...      0\n",
       "2        Rooms are nice but for elderly a bit difficul...      0\n",
       "3        My room was dirty and I was afraid to walk ba...      0\n",
       "4        You When I booked with your company on line y...      0\n",
       "5        Backyard of the hotel is total mess shouldn t...      0\n",
       "...                                                   ...    ...\n",
       "515731   No parking Public parking garage is 15 Euro p...      0\n",
       "515733   no trolly or staff to help you take the lugga...      0\n",
       "515734           The hotel looks like 3 but surely not 4       0\n",
       "515735   The ac was useless It was a hot week in vienn...      0\n",
       "515737       I was in 3rd floor It didn t work Free Wife       0\n",
       "\n",
       "[345057 rows x 2 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1_positive.append(df1_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515731</th>\n",
       "      <td>No parking Public parking garage is 15 Euro p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781382 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  Class\n",
       "0        Only the park outside of the hotel was beauti...      1\n",
       "1        No real complaints the hotel was great great ...      1\n",
       "2        Location was good and staff were ok It is cut...      1\n",
       "3        Great location in nice surroundings the bar a...      1\n",
       "4         Amazing location and building Romantic setting       1\n",
       "...                                                   ...    ...\n",
       "515731   No parking Public parking garage is 15 Euro p...      0\n",
       "515733   no trolly or staff to help you take the lugga...      0\n",
       "515734           The hotel looks like 3 but surely not 4       0\n",
       "515735   The ac was useless It was a hot week in vienn...      0\n",
       "515737       I was in 3rd floor It didn t work Free Wife       0\n",
       "\n",
       "[781382 rows x 2 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the wordnet object value corresponding to the POS tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "            \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", \n",
    "            'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \n",
    "            'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', \n",
    "            'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of',\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "            'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', \n",
    "            'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', \n",
    "            'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', \n",
    "            'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", \n",
    "            \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', \"aren't\", 'couldn', \n",
    "            \"couldn't\", \"hadn't\", \"hasn't\", \n",
    "            \"haven't\", \"isn't\", 'ma', \"mightn't\", \"mustn't\", \"needn't\" , \"shan't\", 'shouldn', 'wasn', \"weren't\"]\n",
    "\n",
    "\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "# clean text data\n",
    "df1[\"lemmatized_comment\"] = df1[\"review\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>park outside hotel beautiful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no real complaint hotel great great location s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location good staff ok cute hotel breakfast ra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great location nice surroundings bar restauran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amaze location building romantic setting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515731</th>\n",
       "      <td>no park public parking garage euro per day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly staff help take luggage room</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>hotel look like surely not</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>ac useless hot week vienna give hot air</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>floor didn work free wife</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781382 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       lemmatized_comment  Class\n",
       "0                            park outside hotel beautiful      1\n",
       "1       no real complaint hotel great great location s...      1\n",
       "2       location good staff ok cute hotel breakfast ra...      1\n",
       "3       great location nice surroundings bar restauran...      1\n",
       "4                amaze location building romantic setting      1\n",
       "...                                                   ...    ...\n",
       "515731         no park public parking garage euro per day      0\n",
       "515733             no trolly staff help take luggage room      0\n",
       "515734                         hotel look like surely not      0\n",
       "515735            ac useless hot week vienna give hot air      0\n",
       "515737                          floor didn work free wife      0\n",
       "\n",
       "[781382 rows x 2 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['lemmatized_comment','Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train, test = train_test_split(df1, random_state=42, test_size=0.30, shuffle=True)\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train.lemmatized_comment)\n",
    "vectorizer.fit(test.lemmatized_comment)\n",
    "x_train = vectorizer.transform(train.lemmatized_comment)\n",
    "y_train = train[['Class']]\n",
    "x_test = vectorizer.transform(test.lemmatized_comment)\n",
    "y_test = test[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamete Tuning\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score\n",
    "from hyperopt import hp, tpe\n",
    "import xgboost as xgb\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "def objective(params):\n",
    "   \n",
    "    params = {'n_estimators': int(params['n_estimators']),\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_child_weight': int(params['min_child_weight']),\n",
    "              'learning_rate' : float(params['learning_rate']),\n",
    "              'gamma': float(params['gamma']),\n",
    "              'colsample_bytree': float(params['colsample_bytree']),\n",
    "              'subsample': float(params['subsample']),\n",
    "              'colsample_bylevel': float(params['colsample_bylevel'])\n",
    "#               ,'class_weight':str(params['class_weight'])\n",
    "             }\n",
    "   \n",
    "    clf = xgb.XGBClassifier(random_state=42, **params)\n",
    "    score = cross_val_score(clf,features_new,labels, scoring=auc_scorer, cv=StratifiedKFold(n_splits=5)).mean()\n",
    "    print(\"AUC {:.3f} params {}\".format(score, params))\n",
    "    return -score\n",
    "\n",
    "space = {\n",
    "    'learning_rate':    hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(1, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'gamma' : hp.uniform('gamma', 0.1, 1.5),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 0.9),\n",
    "    'subsample':        hp.uniform('subsample', 0.7, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.3, 0.8),\n",
    "    'n_estimators':     hp.choice('n_estimators', np.arange(10, 1100, 50, dtype=int)),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100)\n",
    "for i in best.keys():\n",
    "    best[i] = int(best[i])\n",
    "\n",
    "best_model = xgb.XGBClassifier(random_state=42, **best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib64/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.5593257295147386,\n",
       "              colsample_bytree=0.4908567846524142, gamma=1.1020474587964464,\n",
       "              learning_rate=0.09520194824175505, max_delta_step=0, max_depth=80,\n",
       "              min_child_weight=1, missing=None, n_estimators=510, n_jobs=1,\n",
       "              nthread=None, num_class=2, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=0.7622694310500184)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb_model =  xgb.XGBClassifier(objective='multi:softprob', num_class=2, n_estimators= 510, max_depth= 80, min_child_weight= 1, learning_rate= 0.09520194824175505, gamma= 1.1020474587964464,\n",
    "                                      colsample_bytree= 0.4908567846524142, subsample= 0.7622694310500184, colsample_bylevel= 0.5593257295147386)\n",
    "                                          \n",
    "            \n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96    130679\n",
      "           1       0.94      0.95      0.95    103736\n",
      "\n",
      "    accuracy                           0.95    234415\n",
      "   macro avg       0.95      0.95      0.95    234415\n",
      "weighted avg       0.95      0.95      0.95    234415\n",
      "\n",
      "ROC_AUC score: 0.95%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"ROC_AUC score: %.2f%%\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = vectorizer.transform([\"bad hotel dirty washroom\",\"good stay owner supportive\"])\n",
    "y_pred = xgb_model.predict(sample)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.14%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93      1150\n",
      "           1       0.94      0.85      0.89       858\n",
      "\n",
      "    accuracy                           0.91      2008\n",
      "   macro avg       0.92      0.90      0.91      2008\n",
      "weighted avg       0.91      0.91      0.91      2008\n",
      "\n",
      "ROC_AUC is 0.903372859025033\n",
      "[[1102   48]\n",
      " [ 130  728]]\n"
     ]
    }
   ],
   "source": [
    "sample = vectorizer.transform(resampled_df['lemmatized_comment'])\n",
    "y_pred = xgb_model.predict(sample)\n",
    "y_pred_prob = xgb_model.predict_proba(sample)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(resampled_df['Class'], predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(metrics.classification_report(resampled_df['Class'], y_pred))\n",
    "print('ROC_AUC is {}'.format(metrics.roc_auc_score(resampled_df['Class'], y_pred)))\n",
    "print(confusion_matrix(resampled_df['Class'], y_pred, labels=[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RoBERTa\n",
    "\n",
    "  \n",
    "# import pandas as pd\n",
    "# from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# # Train and Evaluation data needs to be in a Pandas Dataframe of two columns. The first column is the text with type str, and the second column is the label with type int.\n",
    "# train_df = train[['lemmatized_comment','Class']]\n",
    "\n",
    "# eval_df = test[['lemmatized_comment','Class']]\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model = ClassificationModel(\"roberta\", \"roberta-base\", use_cuda=False)\n",
    "\n",
    "# # Train the model\n",
    "# model.train_model(train_df, use_cuda=False, output_dir='outputs2')\n",
    "\n",
    "# # Evaluate the model\n",
    "# result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "resampled_df['prediction0'] = y_pred_prob[:,0]\n",
    "resampled_df['prediction1'] = y_pred_prob[:,1]\n",
    "resampled_df['prediction'] = predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OYO ID</th>\n",
       "      <th>Hotel ID</th>\n",
       "      <th>OYO Product</th>\n",
       "      <th>Feedback ID</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Rating</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>...</th>\n",
       "      <th>Pricing</th>\n",
       "      <th>Default</th>\n",
       "      <th>Classification</th>\n",
       "      <th>comment(1cleaning)</th>\n",
       "      <th>langid</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>Class</th>\n",
       "      <th>prediction0</th>\n",
       "      <th>prediction1</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1062</td>\n",
       "      <td>MRT042</td>\n",
       "      <td>46039</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60144582</td>\n",
       "      <td>118672380</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>i had a great stay hotel staff was very suppor...</td>\n",
       "      <td>en</td>\n",
       "      <td>great stay hotel staff supportive kind hearted...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.996339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>KOL1340</td>\n",
       "      <td>82429</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60156829</td>\n",
       "      <td>118141552</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>worst ever oyo experienced no oyo sign board m...</td>\n",
       "      <td>en</td>\n",
       "      <td>worst ever oyo experienced no oyo sign board m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976968</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737</td>\n",
       "      <td>ASR293</td>\n",
       "      <td>58291</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60168982</td>\n",
       "      <td>118586097</td>\n",
       "      <td>bulk_upload</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "      <td>one of the best properties we have ever been i...</td>\n",
       "      <td>en</td>\n",
       "      <td>one best property ever would like visit strong...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188093</td>\n",
       "      <td>0.811907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465</td>\n",
       "      <td>GRG1010</td>\n",
       "      <td>40843</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60178229</td>\n",
       "      <td>118844212</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>everything is good no complaints staff behavio...</td>\n",
       "      <td>en</td>\n",
       "      <td>everything good no complaint staff behaviour p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020298</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>654</td>\n",
       "      <td>DEL775</td>\n",
       "      <td>15322</td>\n",
       "      <td>SMART</td>\n",
       "      <td>60179150</td>\n",
       "      <td>118417540</td>\n",
       "      <td>Android App</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>one of the best hotel through oyo i recommend ...</td>\n",
       "      <td>en</td>\n",
       "      <td>one best hotel oyo recommend hotel guest room ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.991227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>905</td>\n",
       "      <td>DEL1525</td>\n",
       "      <td>55641</td>\n",
       "      <td>SPOT ON</td>\n",
       "      <td>61373230</td>\n",
       "      <td>118489815</td>\n",
       "      <td>Integrated OTA</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bad</td>\n",
       "      <td>refused to provide a discount for booking i ca...</td>\n",
       "      <td>en</td>\n",
       "      <td>refuse provide discount book say anything posi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961890</td>\n",
       "      <td>0.038110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>989</td>\n",
       "      <td>GZB108</td>\n",
       "      <td>46852</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61382951</td>\n",
       "      <td>121800300</td>\n",
       "      <td>IOS App</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>the curtains were very thin and incapable to k...</td>\n",
       "      <td>en</td>\n",
       "      <td>curtain thin incapable keep sunlight away cann...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988688</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>842</td>\n",
       "      <td>SRG102</td>\n",
       "      <td>56126</td>\n",
       "      <td>SMART</td>\n",
       "      <td>61390504</td>\n",
       "      <td>117518389</td>\n",
       "      <td>Android App</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bad</td>\n",
       "      <td>no local ids cards accepted and unmarried coup...</td>\n",
       "      <td>en</td>\n",
       "      <td>no local id card accept unmarried couple not w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994857</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2199</td>\n",
       "      <td>DEL1593</td>\n",
       "      <td>57984</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>61390678</td>\n",
       "      <td>122345895</td>\n",
       "      <td>Crs</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bad</td>\n",
       "      <td>wash room was not clean room was not clean pro...</td>\n",
       "      <td>en</td>\n",
       "      <td>wash room not clean room not clean properly co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>1149</td>\n",
       "      <td>MUM1123</td>\n",
       "      <td>59540</td>\n",
       "      <td>CapitalO</td>\n",
       "      <td>61395280</td>\n",
       "      <td>122677830</td>\n",
       "      <td>Crs</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good</td>\n",
       "      <td>it was good stay reception people was very rud...</td>\n",
       "      <td>en</td>\n",
       "      <td>good stay reception people rude payment issue ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956377</td>\n",
       "      <td>0.043623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   OYO ID  Hotel ID OYO Product  Feedback ID  Booking ID  \\\n",
       "0           1062   MRT042     46039       SMART     60144582   118672380   \n",
       "1            283  KOL1340     82429       SMART     60156829   118141552   \n",
       "2            737   ASR293     58291       SMART     60168982   118586097   \n",
       "3           1465  GRG1010     40843       SMART     60178229   118844212   \n",
       "4            654   DEL775     15322       SMART     60179150   118417540   \n",
       "...          ...      ...       ...         ...          ...         ...   \n",
       "2383         905  DEL1525     55641     SPOT ON     61373230   118489815   \n",
       "2384         989   GZB108     46852       SMART     61382951   121800300   \n",
       "2385         842   SRG102     56126       SMART     61390504   117518389   \n",
       "2386        2199  DEL1593     57984   Townhouse     61390678   122345895   \n",
       "2388        1149  MUM1123     59540    CapitalO     61395280   122677830   \n",
       "\n",
       "              Source  Rating  L1  L2  ... Pricing  Default  Classification  \\\n",
       "0        Android App       5 NaN NaN  ...   False    False            Good   \n",
       "1        Android App       1 NaN NaN  ...   False    False             Bad   \n",
       "2        bulk_upload       0 NaN NaN  ...   False     True            Good   \n",
       "3        Android App       5 NaN NaN  ...   False    False            Good   \n",
       "4        Android App       5 NaN NaN  ...   False    False            Good   \n",
       "...              ...     ...  ..  ..  ...     ...      ...             ...   \n",
       "2383  Integrated OTA       2 NaN NaN  ...   False     True             Bad   \n",
       "2384         IOS App       3 NaN NaN  ...   False    False             Bad   \n",
       "2385     Android App       3 NaN NaN  ...   False     True             Bad   \n",
       "2386             Crs       1 NaN NaN  ...   False    False             Bad   \n",
       "2388             Crs       3 NaN NaN  ...   False    False            Good   \n",
       "\n",
       "                                     comment(1cleaning)  langid  \\\n",
       "0     i had a great stay hotel staff was very suppor...      en   \n",
       "1     worst ever oyo experienced no oyo sign board m...      en   \n",
       "2     one of the best properties we have ever been i...      en   \n",
       "3     everything is good no complaints staff behavio...      en   \n",
       "4     one of the best hotel through oyo i recommend ...      en   \n",
       "...                                                 ...     ...   \n",
       "2383  refused to provide a discount for booking i ca...      en   \n",
       "2384  the curtains were very thin and incapable to k...      en   \n",
       "2385  no local ids cards accepted and unmarried coup...      en   \n",
       "2386  wash room was not clean room was not clean pro...      en   \n",
       "2388  it was good stay reception people was very rud...      en   \n",
       "\n",
       "                                     lemmatized_comment  Class  prediction0  \\\n",
       "0     great stay hotel staff supportive kind hearted...      1     0.003661   \n",
       "1     worst ever oyo experienced no oyo sign board m...      0     0.976968   \n",
       "2     one best property ever would like visit strong...      1     0.188093   \n",
       "3     everything good no complaint staff behaviour p...      1     0.020298   \n",
       "4     one best hotel oyo recommend hotel guest room ...      1     0.008773   \n",
       "...                                                 ...    ...          ...   \n",
       "2383  refuse provide discount book say anything posi...      0     0.961890   \n",
       "2384  curtain thin incapable keep sunlight away cann...      0     0.988688   \n",
       "2385  no local id card accept unmarried couple not w...      0     0.994857   \n",
       "2386  wash room not clean room not clean properly co...      0     0.997769   \n",
       "2388  good stay reception people rude payment issue ...      1     0.956377   \n",
       "\n",
       "      prediction1  prediction  \n",
       "0        0.996339           1  \n",
       "1        0.023032           0  \n",
       "2        0.811907           1  \n",
       "3        0.979702           1  \n",
       "4        0.991227           1  \n",
       "...           ...         ...  \n",
       "2383     0.038110           0  \n",
       "2384     0.011312           0  \n",
       "2385     0.005143           0  \n",
       "2386     0.002231           0  \n",
       "2388     0.043623           0  \n",
       "\n",
       "[2008 rows x 39 columns]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.90\n",
      "Precision: 0.99\n",
      "Recall: 0.70\n",
      "F1 score: 0.82\n",
      "\n",
      "\n",
      "Threshold: 0.80\n",
      "Precision: 0.98\n",
      "Recall: 0.78\n",
      "F1 score: 0.87\n",
      "\n",
      "\n",
      "Threshold: 0.70\n",
      "Precision: 0.98\n",
      "Recall: 0.83\n",
      "F1 score: 0.90\n",
      "\n",
      "\n",
      "Threshold: 0.60\n",
      "Precision: 0.97\n",
      "Recall: 0.86\n",
      "F1 score: 0.91\n",
      "\n",
      "\n",
      "Threshold: 0.50\n",
      "Precision: 0.96\n",
      "Recall: 0.89\n",
      "F1 score: 0.93\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "threshold = [0.9,0.8,0.7,0.6,0.5]\n",
    "for t in threshold:\n",
    "    print(\"Threshold: %.2f\" % (t))\n",
    "    threshold_df = resampled_df[(resampled_df.prediction0 > t) | (resampled_df.prediction1 > t)]\n",
    "    tp = confusion_matrix(threshold_df['Class'], threshold_df['prediction'], labels=[0,1])[0][0]\n",
    "    fn = confusion_matrix(threshold_df['Class'], threshold_df['prediction'], labels=[0,1])[1][0] + (resampled_df.shape[0] - threshold_df.shape[0])\n",
    "    tn = confusion_matrix(threshold_df['Class'], threshold_df['prediction'], labels=[0,1])[0][1]\n",
    "    fp = confusion_matrix(threshold_df['Class'], threshold_df['prediction'], labels=[0,1])[1][1]\n",
    "    precision = float(tp) / (tp + tn)\n",
    "    recall = float(tp) / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"Precision: %.2f\" % (precision))\n",
    "    print(\"Recall: %.2f\" % (recall))\n",
    "    print(\"F1 score: %.2f\" % (f1))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
